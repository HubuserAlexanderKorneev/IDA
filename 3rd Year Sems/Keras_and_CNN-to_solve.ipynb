{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully connected net в Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# загрузим датасет MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем one-hot encoding для таргетов\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# опишем модель\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(70, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s - loss: 2.0553 - acc: 0.4949 - val_loss: 1.7960 - val_acc: 0.6783\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s - loss: 1.5799 - acc: 0.7172 - val_loss: 1.3510 - val_acc: 0.7644\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s - loss: 1.1801 - acc: 0.7918 - val_loss: 1.0117 - val_acc: 0.8201\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.8991 - acc: 0.8353 - val_loss: 0.7895 - val_acc: 0.8504\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.7206 - acc: 0.8586 - val_loss: 0.6503 - val_acc: 0.87420.85\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.6053 - acc: 0.8749 - val_loss: 0.5578 - val_acc: 0.8869\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.5266 - acc: 0.8870 - val_loss: 0.4950 - val_acc: 0.8945\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.4684 - acc: 0.8952 - val_loss: 0.4424 - val_acc: 0.9024\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.4268 - acc: 0.9015 - val_loss: 0.4060 - val_acc: 0.9055\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3951 - acc: 0.9053 - val_loss: 0.3785 - val_acc: 0.9109\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3695 - acc: 0.9101 - val_loss: 0.3573 - val_acc: 0.9102\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3471 - acc: 0.9136 - val_loss: 0.3361 - val_acc: 0.9176\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3315 - acc: 0.9160 - val_loss: 0.3258 - val_acc: 0.9171\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3168 - acc: 0.9191 - val_loss: 0.3126 - val_acc: 0.9184\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.3045 - acc: 0.9217 - val_loss: 0.3008 - val_acc: 0.9240\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2955 - acc: 0.9235 - val_loss: 0.2975 - val_acc: 0.9213\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2827 - acc: 0.9271 - val_loss: 0.2790 - val_acc: 0.9261\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2740 - acc: 0.9280 - val_loss: 0.2723 - val_acc: 0.9287\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2640 - acc: 0.9303 - val_loss: 0.2625 - val_acc: 0.9298\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2565 - acc: 0.9324 - val_loss: 0.2557 - val_acc: 0.9320\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2513 - acc: 0.9336 - val_loss: 0.2556 - val_acc: 0.9292\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2444 - acc: 0.9349 - val_loss: 0.2493 - val_acc: 0.9332\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2389 - acc: 0.9363 - val_loss: 0.2457 - val_acc: 0.9318\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2335 - acc: 0.9376 - val_loss: 0.2330 - val_acc: 0.9344\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2283 - acc: 0.9388 - val_loss: 0.2308 - val_acc: 0.9380\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2232 - acc: 0.9398 - val_loss: 0.2292 - val_acc: 0.9396\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2210 - acc: 0.9412 - val_loss: 0.2206 - val_acc: 0.9390\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2161 - acc: 0.9414 - val_loss: 0.2276 - val_acc: 0.9360\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2119 - acc: 0.9430 - val_loss: 0.2146 - val_acc: 0.9422\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2080 - acc: 0.9437 - val_loss: 0.2164 - val_acc: 0.9402\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2070 - acc: 0.9434 - val_loss: 0.2147 - val_acc: 0.9409\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2016 - acc: 0.9457 - val_loss: 0.2079 - val_acc: 0.9419\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1948 - acc: 0.9465 - val_loss: 0.2095 - val_acc: 0.9410\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.2003 - acc: 0.9456 - val_loss: 0.2033 - val_acc: 0.9449\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1922 - acc: 0.9474 - val_loss: 0.2052 - val_acc: 0.9435\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1890 - acc: 0.9488 - val_loss: 0.1950 - val_acc: 0.9463\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1866 - acc: 0.9481 - val_loss: 0.1942 - val_acc: 0.9457\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1827 - acc: 0.9507 - val_loss: 0.1962 - val_acc: 0.9440\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1800 - acc: 0.9512 - val_loss: 0.1935 - val_acc: 0.9445\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1791 - acc: 0.9509 - val_loss: 0.1884 - val_acc: 0.9466\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1778 - acc: 0.9514 - val_loss: 0.1843 - val_acc: 0.9474\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1713 - acc: 0.9529 - val_loss: 0.1870 - val_acc: 0.9467\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1707 - acc: 0.9535 - val_loss: 0.1831 - val_acc: 0.9467\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1681 - acc: 0.9529 - val_loss: 0.1808 - val_acc: 0.9474\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1692 - acc: 0.9528 - val_loss: 0.1919 - val_acc: 0.9461\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1678 - acc: 0.9534 - val_loss: 0.1770 - val_acc: 0.9494\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1615 - acc: 0.9551 - val_loss: 0.1780 - val_acc: 0.9510\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1606 - acc: 0.9555 - val_loss: 0.1716 - val_acc: 0.9521\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1596 - acc: 0.9562 - val_loss: 0.1727 - val_acc: 0.95130.956\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 1s - loss: 0.1560 - acc: 0.9574 - val_loss: 0.1735 - val_acc: 0.9526\n",
      "Test loss: 0.173533196527\n",
      "Test accuracy: 0.9526\n"
     ]
    }
   ],
   "source": [
    "#обучим\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.1),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=1000,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1b456a20>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAFNCAYAAABIei33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1vIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b42e908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# динамику обучения можно посмотреть через объект history, которую возвращает model.fit\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Iter num\")\n",
    "plt.plot(history.history[\"loss\"])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy on test\")\n",
    "plt.xlabel(\"Iter num\")\n",
    "plt.plot(history.history[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#сравните графики loss'a и accuracy для разного количества внутренних слоёв FCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ускорения обучения полносвязных нейронных сетей следует применять технику Batch Normalisation. Она преобразует активации нейронов слоя, после которого стоит так, чтобы они имели нулевое матожидание и единичную дисперсию. Такое преобразование позволяет ослабить угасание градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# после каждого Dense слоя сделайте model.add(BatchNormalization())\n",
    "# сравните графики изменения loss и accuracу для сети с BN и без него"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# после каждого Dense слоя сделайте model.add(Dropout(0.25))\n",
    "# сравните графики изменения loss и accuracу для сети с DO и без него"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170426368/170498071 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# загрузим датасет MNIST\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_train[512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e03ef7e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e03f32908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем one-hot encoding для таргетов\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj = np.random.normal(size=(2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e03f06550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU4aKpKb+F+fRg2SIyQ8CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e03bd6cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# описываем модель\n",
    "\n",
    "input_shape=(2, 2, 3)\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, kernel_size=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,kernel_initializer = keras.initializers.Ones()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = model.predict(obj.reshape(1,2,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_6/kernel:0' shape=(2, 2, 3, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_6/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "20400/50000 [===========>..................] - ETA: 211s - loss: 2.1616 - acc: 0.2050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-7bbb218100e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=300\n",
    "epochs=50\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cохранение и загрузка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_dataset = 'oxfordflower17/'\n",
    "\n",
    "if not os.path.isdir(path_to_dataset):\n",
    "    ! wget http://www.robots.ox.ac.uk/~vgg/data/bicos/data/oxfordflower17.tar\n",
    "    ! tar -xf oxfordflower17.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ..., 16 16 16]\n",
      "1360\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import scipy.io as  io\n",
    "labels = scipy.io.loadmat(path_to_dataset + 'imagelabels.mat')['labels'][0]\n",
    "labels -= 1\n",
    "print(labels)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1360\n"
     ]
    }
   ],
   "source": [
    "path_to_images = path_to_dataset + 'jpg/'\n",
    "images = os.listdir(path_to_images)\n",
    "images = [path_to_images+i for i in images if i.endswith('.jpg')]\n",
    "images.sort()\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/binom/.anaconda3/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage.transform as skit\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for i,image in enumerate(images):\n",
    "    if i % 80 == 0: \n",
    "        perm = np.random.permutation(80)\n",
    "        \n",
    "    image = cv2.imread(images[i], cv2.IMREAD_COLOR)[:,:,[2,1,0]]\n",
    "    image = skit.rescale(image, (230/image.shape[0], 230/image.shape[1]))\n",
    "        \n",
    "    if perm[i % 80] < 60:\n",
    "        train_data.append(image)\n",
    "        train_labels.append(labels[i])\n",
    "    else:\n",
    "        test_data.append(image)\n",
    "        test_labels.append(labels[i])\n",
    "\n",
    "        \n",
    "x_train = np.array(train_data)\n",
    "x_test = np.array(test_data)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем one-hot encoding для таргетов\n",
    "y_train = keras.utils.to_categorical(y_train, 17)\n",
    "y_test = keras.utils.to_categorical(y_test, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1020 samples, validate on 340 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 506s - loss: 2.4967 - acc: 0.2461 - val_loss: 2.3971 - val_acc: 0.2618\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 503s - loss: 1.7292 - acc: 0.5637 - val_loss: 2.0289 - val_acc: 0.3647\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 528s - loss: 1.3294 - acc: 0.7049 - val_loss: 1.4292 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 509s - loss: 1.0214 - acc: 0.7843 - val_loss: 1.2258 - val_acc: 0.5676\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 491s - loss: 0.8425 - acc: 0.8255 - val_loss: 0.8950 - val_acc: 0.7265\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 431s - loss: 0.7005 - acc: 0.8451 - val_loss: 0.8682 - val_acc: 0.7353\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 441s - loss: 0.6159 - acc: 0.8618 - val_loss: 0.7358 - val_acc: 0.7794\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 475s - loss: 0.4900 - acc: 0.9127 - val_loss: 0.6279 - val_acc: 0.8029\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 2304s - loss: 0.4487 - acc: 0.9108 - val_loss: 0.7113 - val_acc: 0.8088\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 928s - loss: 0.3802 - acc: 0.9245 - val_loss: 0.6528 - val_acc: 0.7941\n",
      "0 input_4\n",
      "1 conv2d_232\n",
      "2 batch_normalization_232\n",
      "3 activation_231\n",
      "4 conv2d_233\n",
      "5 batch_normalization_233\n",
      "6 activation_232\n",
      "7 conv2d_234\n",
      "8 batch_normalization_234\n",
      "9 activation_233\n",
      "10 max_pooling2d_12\n",
      "11 conv2d_235\n",
      "12 batch_normalization_235\n",
      "13 activation_234\n",
      "14 conv2d_236\n",
      "15 batch_normalization_236\n",
      "16 activation_235\n",
      "17 max_pooling2d_13\n",
      "18 conv2d_240\n",
      "19 batch_normalization_240\n",
      "20 activation_239\n",
      "21 conv2d_238\n",
      "22 conv2d_241\n",
      "23 batch_normalization_238\n",
      "24 batch_normalization_241\n",
      "25 activation_237\n",
      "26 activation_240\n",
      "27 average_pooling2d_23\n",
      "28 conv2d_237\n",
      "29 conv2d_239\n",
      "30 conv2d_242\n",
      "31 conv2d_243\n",
      "32 batch_normalization_237\n",
      "33 batch_normalization_239\n",
      "34 batch_normalization_242\n",
      "35 batch_normalization_243\n",
      "36 activation_236\n",
      "37 activation_238\n",
      "38 activation_241\n",
      "39 activation_242\n",
      "40 mixed0\n",
      "41 conv2d_247\n",
      "42 batch_normalization_247\n",
      "43 activation_246\n",
      "44 conv2d_245\n",
      "45 conv2d_248\n",
      "46 batch_normalization_245\n",
      "47 batch_normalization_248\n",
      "48 activation_244\n",
      "49 activation_247\n",
      "50 average_pooling2d_24\n",
      "51 conv2d_244\n",
      "52 conv2d_246\n",
      "53 conv2d_249\n",
      "54 conv2d_250\n",
      "55 batch_normalization_244\n",
      "56 batch_normalization_246\n",
      "57 batch_normalization_249\n",
      "58 batch_normalization_250\n",
      "59 activation_243\n",
      "60 activation_245\n",
      "61 activation_248\n",
      "62 activation_249\n",
      "63 mixed1\n",
      "64 conv2d_254\n",
      "65 batch_normalization_254\n",
      "66 activation_253\n",
      "67 conv2d_252\n",
      "68 conv2d_255\n",
      "69 batch_normalization_252\n",
      "70 batch_normalization_255\n",
      "71 activation_251\n",
      "72 activation_254\n",
      "73 average_pooling2d_25\n",
      "74 conv2d_251\n",
      "75 conv2d_253\n",
      "76 conv2d_256\n",
      "77 conv2d_257\n",
      "78 batch_normalization_251\n",
      "79 batch_normalization_253\n",
      "80 batch_normalization_256\n",
      "81 batch_normalization_257\n",
      "82 activation_250\n",
      "83 activation_252\n",
      "84 activation_255\n",
      "85 activation_256\n",
      "86 mixed2\n",
      "87 conv2d_259\n",
      "88 batch_normalization_259\n",
      "89 activation_258\n",
      "90 conv2d_260\n",
      "91 batch_normalization_260\n",
      "92 activation_259\n",
      "93 conv2d_258\n",
      "94 conv2d_261\n",
      "95 batch_normalization_258\n",
      "96 batch_normalization_261\n",
      "97 activation_257\n",
      "98 activation_260\n",
      "99 max_pooling2d_14\n",
      "100 mixed3\n",
      "101 conv2d_266\n",
      "102 batch_normalization_266\n",
      "103 activation_265\n",
      "104 conv2d_267\n",
      "105 batch_normalization_267\n",
      "106 activation_266\n",
      "107 conv2d_263\n",
      "108 conv2d_268\n",
      "109 batch_normalization_263\n",
      "110 batch_normalization_268\n",
      "111 activation_262\n",
      "112 activation_267\n",
      "113 conv2d_264\n",
      "114 conv2d_269\n",
      "115 batch_normalization_264\n",
      "116 batch_normalization_269\n",
      "117 activation_263\n",
      "118 activation_268\n",
      "119 average_pooling2d_26\n",
      "120 conv2d_262\n",
      "121 conv2d_265\n",
      "122 conv2d_270\n",
      "123 conv2d_271\n",
      "124 batch_normalization_262\n",
      "125 batch_normalization_265\n",
      "126 batch_normalization_270\n",
      "127 batch_normalization_271\n",
      "128 activation_261\n",
      "129 activation_264\n",
      "130 activation_269\n",
      "131 activation_270\n",
      "132 mixed4\n",
      "133 conv2d_276\n",
      "134 batch_normalization_276\n",
      "135 activation_275\n",
      "136 conv2d_277\n",
      "137 batch_normalization_277\n",
      "138 activation_276\n",
      "139 conv2d_273\n",
      "140 conv2d_278\n",
      "141 batch_normalization_273\n",
      "142 batch_normalization_278\n",
      "143 activation_272\n",
      "144 activation_277\n",
      "145 conv2d_274\n",
      "146 conv2d_279\n",
      "147 batch_normalization_274\n",
      "148 batch_normalization_279\n",
      "149 activation_273\n",
      "150 activation_278\n",
      "151 average_pooling2d_27\n",
      "152 conv2d_272\n",
      "153 conv2d_275\n",
      "154 conv2d_280\n",
      "155 conv2d_281\n",
      "156 batch_normalization_272\n",
      "157 batch_normalization_275\n",
      "158 batch_normalization_280\n",
      "159 batch_normalization_281\n",
      "160 activation_271\n",
      "161 activation_274\n",
      "162 activation_279\n",
      "163 activation_280\n",
      "164 mixed5\n",
      "165 conv2d_286\n",
      "166 batch_normalization_286\n",
      "167 activation_285\n",
      "168 conv2d_287\n",
      "169 batch_normalization_287\n",
      "170 activation_286\n",
      "171 conv2d_283\n",
      "172 conv2d_288\n",
      "173 batch_normalization_283\n",
      "174 batch_normalization_288\n",
      "175 activation_282\n",
      "176 activation_287\n",
      "177 conv2d_284\n",
      "178 conv2d_289\n",
      "179 batch_normalization_284\n",
      "180 batch_normalization_289\n",
      "181 activation_283\n",
      "182 activation_288\n",
      "183 average_pooling2d_28\n",
      "184 conv2d_282\n",
      "185 conv2d_285\n",
      "186 conv2d_290\n",
      "187 conv2d_291\n",
      "188 batch_normalization_282\n",
      "189 batch_normalization_285\n",
      "190 batch_normalization_290\n",
      "191 batch_normalization_291\n",
      "192 activation_281\n",
      "193 activation_284\n",
      "194 activation_289\n",
      "195 activation_290\n",
      "196 mixed6\n",
      "197 conv2d_296\n",
      "198 batch_normalization_296\n",
      "199 activation_295\n",
      "200 conv2d_297\n",
      "201 batch_normalization_297\n",
      "202 activation_296\n",
      "203 conv2d_293\n",
      "204 conv2d_298\n",
      "205 batch_normalization_293\n",
      "206 batch_normalization_298\n",
      "207 activation_292\n",
      "208 activation_297\n",
      "209 conv2d_294\n",
      "210 conv2d_299\n",
      "211 batch_normalization_294\n",
      "212 batch_normalization_299\n",
      "213 activation_293\n",
      "214 activation_298\n",
      "215 average_pooling2d_29\n",
      "216 conv2d_292\n",
      "217 conv2d_295\n",
      "218 conv2d_300\n",
      "219 conv2d_301\n",
      "220 batch_normalization_292\n",
      "221 batch_normalization_295\n",
      "222 batch_normalization_300\n",
      "223 batch_normalization_301\n",
      "224 activation_291\n",
      "225 activation_294\n",
      "226 activation_299\n",
      "227 activation_300\n",
      "228 mixed7\n",
      "229 conv2d_304\n",
      "230 batch_normalization_304\n",
      "231 activation_303\n",
      "232 conv2d_305\n",
      "233 batch_normalization_305\n",
      "234 activation_304\n",
      "235 conv2d_302\n",
      "236 conv2d_306\n",
      "237 batch_normalization_302\n",
      "238 batch_normalization_306\n",
      "239 activation_301\n",
      "240 activation_305\n",
      "241 conv2d_303\n",
      "242 conv2d_307\n",
      "243 batch_normalization_303\n",
      "244 batch_normalization_307\n",
      "245 activation_302\n",
      "246 activation_306\n",
      "247 max_pooling2d_15\n",
      "248 mixed8\n",
      "249 conv2d_312\n",
      "250 batch_normalization_312\n",
      "251 activation_311\n",
      "252 conv2d_309\n",
      "253 conv2d_313\n",
      "254 batch_normalization_309\n",
      "255 batch_normalization_313\n",
      "256 activation_308\n",
      "257 activation_312\n",
      "258 conv2d_310\n",
      "259 conv2d_311\n",
      "260 conv2d_314\n",
      "261 conv2d_315\n",
      "262 average_pooling2d_30\n",
      "263 conv2d_308\n",
      "264 batch_normalization_310\n",
      "265 batch_normalization_311\n",
      "266 batch_normalization_314\n",
      "267 batch_normalization_315\n",
      "268 conv2d_316\n",
      "269 batch_normalization_308\n",
      "270 activation_309\n",
      "271 activation_310\n",
      "272 activation_313\n",
      "273 activation_314\n",
      "274 batch_normalization_316\n",
      "275 activation_307\n",
      "276 mixed9_0\n",
      "277 concatenate_5\n",
      "278 activation_315\n",
      "279 mixed9\n",
      "280 conv2d_321\n",
      "281 batch_normalization_321\n",
      "282 activation_320\n",
      "283 conv2d_318\n",
      "284 conv2d_322\n",
      "285 batch_normalization_318\n",
      "286 batch_normalization_322\n",
      "287 activation_317\n",
      "288 activation_321\n",
      "289 conv2d_319\n",
      "290 conv2d_320\n",
      "291 conv2d_323\n",
      "292 conv2d_324\n",
      "293 average_pooling2d_31\n",
      "294 conv2d_317\n",
      "295 batch_normalization_319\n",
      "296 batch_normalization_320\n",
      "297 batch_normalization_323\n",
      "298 batch_normalization_324\n",
      "299 conv2d_325\n",
      "300 batch_normalization_317\n",
      "301 activation_318\n",
      "302 activation_319\n",
      "303 activation_322\n",
      "304 activation_323\n",
      "305 batch_normalization_325\n",
      "306 activation_316\n",
      "307 mixed9_1\n",
      "308 concatenate_6\n",
      "309 activation_324\n",
      "310 mixed10\n",
      "Train on 1020 samples, validate on 340 samples\n",
      "Epoch 1/50\n",
      "1020/1020 [==============================] - 1596s - loss: 0.3861 - acc: 0.9078 - val_loss: 0.5772 - val_acc: 0.8294\n",
      "Epoch 2/50\n",
      "1020/1020 [==============================] - 744s - loss: 0.3142 - acc: 0.9510 - val_loss: 0.5208 - val_acc: 0.8559\n",
      "Epoch 3/50\n",
      "1020/1020 [==============================] - 850s - loss: 0.2792 - acc: 0.9657 - val_loss: 0.4939 - val_acc: 0.8618\n",
      "Epoch 4/50\n",
      "1020/1020 [==============================] - 2562s - loss: 0.2442 - acc: 0.9725 - val_loss: 0.4815 - val_acc: 0.8706\n",
      "Epoch 5/50\n",
      "1020/1020 [==============================] - 621s - loss: 0.2370 - acc: 0.9755 - val_loss: 0.4757 - val_acc: 0.8824\n",
      "Epoch 6/50\n",
      "1020/1020 [==============================] - 3988s - loss: 0.2312 - acc: 0.9804 - val_loss: 0.4713 - val_acc: 0.8912\n",
      "Epoch 7/50\n",
      "1020/1020 [==============================] - 521s - loss: 0.2141 - acc: 0.9725 - val_loss: 0.4681 - val_acc: 0.8824\n",
      "Epoch 8/50\n",
      "1020/1020 [==============================] - 580s - loss: 0.1798 - acc: 0.9833 - val_loss: 0.4652 - val_acc: 0.8824\n",
      "Epoch 9/50\n",
      "1020/1020 [==============================] - 4209s - loss: 0.1803 - acc: 0.9912 - val_loss: 0.4642 - val_acc: 0.8794\n",
      "Epoch 10/50\n",
      "1020/1020 [==============================] - 515s - loss: 0.1876 - acc: 0.9882 - val_loss: 0.4608 - val_acc: 0.8794\n",
      "Epoch 11/50\n",
      "1020/1020 [==============================] - 556s - loss: 0.1739 - acc: 0.9912 - val_loss: 0.4587 - val_acc: 0.8824\n",
      "Epoch 12/50\n",
      "1020/1020 [==============================] - 663s - loss: 0.1831 - acc: 0.9833 - val_loss: 0.4547 - val_acc: 0.8794\n",
      "Epoch 13/50\n",
      "1020/1020 [==============================] - 1846s - loss: 0.1562 - acc: 0.9961 - val_loss: 0.4533 - val_acc: 0.8794\n",
      "Epoch 14/50\n",
      "1020/1020 [==============================] - 547s - loss: 0.1492 - acc: 0.9892 - val_loss: 0.4514 - val_acc: 0.8794\n",
      "Epoch 15/50\n",
      "1020/1020 [==============================] - 713s - loss: 0.1385 - acc: 0.9971 - val_loss: 0.4490 - val_acc: 0.8824\n",
      "Epoch 16/50\n",
      "1020/1020 [==============================] - 7901s - loss: 0.1365 - acc: 0.9931 - val_loss: 0.4461 - val_acc: 0.8824\n",
      "Epoch 17/50\n",
      "1020/1020 [==============================] - 612s - loss: 0.1468 - acc: 0.9863 - val_loss: 0.4430 - val_acc: 0.8853\n",
      "Epoch 18/50\n",
      "1020/1020 [==============================] - 579s - loss: 0.1303 - acc: 0.9961 - val_loss: 0.4403 - val_acc: 0.8882\n",
      "Epoch 19/50\n",
      "1020/1020 [==============================] - 3430s - loss: 0.1331 - acc: 0.9961 - val_loss: 0.4382 - val_acc: 0.8882\n",
      "Epoch 20/50\n",
      "1020/1020 [==============================] - 514s - loss: 0.1273 - acc: 0.9971 - val_loss: 0.4356 - val_acc: 0.8882\n",
      "Epoch 21/50\n",
      "1020/1020 [==============================] - 513s - loss: 0.1251 - acc: 0.9961 - val_loss: 0.4331 - val_acc: 0.8912\n",
      "Epoch 22/50\n",
      "1020/1020 [==============================] - 875s - loss: 0.1243 - acc: 0.9912 - val_loss: 0.4299 - val_acc: 0.8882\n",
      "Epoch 23/50\n",
      "1000/1020 [============================>.] - ETA: 7s - loss: 0.1217 - acc: 0.9940 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1f14e20063ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1195\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1196\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m                                                        verbose=0)\n\u001b[0m\u001b[1;32m   1198\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1337\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(input_shape=(230, 230, 3),weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(30, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(17, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=50,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=50,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
